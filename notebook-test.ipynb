{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Clone Dataset and read it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'multiged-2023' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/spraakbanken/multiged-2023.git"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('multiged-2023/english/en_fce_dev.tsv',sep='\\t', header=None)\n",
    "df.columns = ['word', 'label']\n",
    "df['label'] = df['label'].fillna('c')\n",
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "id": "Ywsrb0C8l3sZ",
    "outputId": "25fc6b40-04b8-46fa-f1de-f4736d797897"
   },
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "           word label\n0          13th     c\n1          June     c\n2          2000     c\n3          Dear     c\n4            Ms     c\n...         ...   ...\n34743       see     i\n34744  pleasure     c\n34745        in     c\n34746        it     c\n34747         .     c\n\n[34748 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13th</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>June</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2000</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Dear</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ms</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>34743</th>\n      <td>see</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>34744</th>\n      <td>pleasure</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>34745</th>\n      <td>in</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>34746</th>\n      <td>it</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>34747</th>\n      <td>.</td>\n      <td>c</td>\n    </tr>\n  </tbody>\n</table>\n<p>34748 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make traning set ready for lanuage models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def find_sentence_firsts(word_list):\n",
    "    sentence_first = [0]\n",
    "    lookup = [1]\n",
    "    sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    for i in range(len(word_list)):\n",
    "        lookup.append(len(sent_detector.tokenize(' '.join(word_list[sentence_first[-1]:i+1]))))\n",
    "        if lookup[i+1] > lookup[i]:\n",
    "            sentence_first.append(i)\n",
    "    sentence_first.append(i)\n",
    "    return sentence_first\n",
    "sentence_firsts = find_sentence_firsts(df.word)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "prompts = []\n",
    "responces = []\n",
    "for i in range(1, len(sentence_firsts)):\n",
    "    prompts.append(\" \".join(df.word[sentence_firsts[i-1]:sentence_firsts[i]]))\n",
    "    responces.append(df[sentence_firsts[i-1]:sentence_firsts[i]].to_csv(sep='\\t', index=False, header=False))\n",
    "\n",
    "df_train = pd.DataFrame({'prompt': prompts, 'completion': responces})\n",
    "df_train.to_csv('my_train_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 prompt  \\\n0     13th June 2000 Dear Ms Helen Ryan Competition ...   \n1     I am proud of winning it and would like to say...   \n2     I am therefore writing to give you my further ...   \n3     First of all , I am a student and would like t...   \n4     Because I intend to take examination in Septen...   \n...                                                 ...   \n1965  It 's hard for me even to emagine the situatio...   \n1966  Probably it is one of the moments when you wan...   \n1967  Another situation is when you have to buy some...   \n1968  Everybody know that , , present presents a pro...   \n1969  However I ca n't agree with opinion that , , S...   \n\n                                             completion  \n0     13th\\tc\\nJune\\tc\\n2000\\tc\\nDear\\tc\\nMs\\tc\\nHel...  \n1     I\\tc\\nam\\tc\\nproud\\tc\\nof\\tc\\nwinning\\tc\\nit\\t...  \n2     I\\tc\\nam\\tc\\ntherefore\\tc\\nwriting\\tc\\nto\\tc\\n...  \n3     First\\tc\\nof\\tc\\nall\\tc\\n,\\tc\\nI\\tc\\nam\\tc\\na\\...  \n4     Because\\ti\\nI\\tc\\nintend\\tc\\nto\\tc\\ntake\\tc\\ne...  \n...                                                 ...  \n1965  It\\tc\\n's\\tc\\nhard\\tc\\nfor\\tc\\nme\\tc\\neven\\tc\\...  \n1966  Probably\\tc\\nit\\tc\\nis\\tc\\none\\tc\\nof\\tc\\nthe\\...  \n1967  Another\\tc\\nsituation\\tc\\nis\\tc\\nwhen\\tc\\nyou\\...  \n1968  Everybody\\tc\\nknow\\ti\\nthat\\tc\\n,\\tc\\n,\\tc\\npr...  \n1969  However\\tc\\nI\\tc\\nca\\tc\\nn't\\tc\\nagree\\tc\\nwit...  \n\n[1970 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>completion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13th June 2000 Dear Ms Helen Ryan Competition ...</td>\n      <td>13th\\tc\\nJune\\tc\\n2000\\tc\\nDear\\tc\\nMs\\tc\\nHel...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I am proud of winning it and would like to say...</td>\n      <td>I\\tc\\nam\\tc\\nproud\\tc\\nof\\tc\\nwinning\\tc\\nit\\t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I am therefore writing to give you my further ...</td>\n      <td>I\\tc\\nam\\tc\\ntherefore\\tc\\nwriting\\tc\\nto\\tc\\n...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>First of all , I am a student and would like t...</td>\n      <td>First\\tc\\nof\\tc\\nall\\tc\\n,\\tc\\nI\\tc\\nam\\tc\\na\\...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Because I intend to take examination in Septen...</td>\n      <td>Because\\ti\\nI\\tc\\nintend\\tc\\nto\\tc\\ntake\\tc\\ne...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1965</th>\n      <td>It 's hard for me even to emagine the situatio...</td>\n      <td>It\\tc\\n's\\tc\\nhard\\tc\\nfor\\tc\\nme\\tc\\neven\\tc\\...</td>\n    </tr>\n    <tr>\n      <th>1966</th>\n      <td>Probably it is one of the moments when you wan...</td>\n      <td>Probably\\tc\\nit\\tc\\nis\\tc\\none\\tc\\nof\\tc\\nthe\\...</td>\n    </tr>\n    <tr>\n      <th>1967</th>\n      <td>Another situation is when you have to buy some...</td>\n      <td>Another\\tc\\nsituation\\tc\\nis\\tc\\nwhen\\tc\\nyou\\...</td>\n    </tr>\n    <tr>\n      <th>1968</th>\n      <td>Everybody know that , , present presents a pro...</td>\n      <td>Everybody\\tc\\nknow\\ti\\nthat\\tc\\n,\\tc\\n,\\tc\\npr...</td>\n    </tr>\n    <tr>\n      <th>1969</th>\n      <td>However I ca n't agree with opinion that , , S...</td>\n      <td>However\\tc\\nI\\tc\\nca\\tc\\nn't\\tc\\nagree\\tc\\nwit...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1970 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using Few-Shot Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import pickle\n",
    "fewshot_data = pickle.load(open('fewshot_data.sav', 'rb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRateLimitError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/lv/4wjmh6d51zv3p9ttk4670pq80000gn/T/ipykernel_21389/90237313.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[0;31m#Using GPT3\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m     response_GPT3 = openai.Completion.create(\n\u001B[0m\u001B[1;32m     24\u001B[0m       \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"text-davinci-003\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m       \u001B[0mprompt\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mprompt\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/openai/lib/python3.9/site-packages/openai/api_resources/completion.py\u001B[0m in \u001B[0;36mcreate\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m     23\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mTryAgain\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mstart\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/openai/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001B[0m in \u001B[0;36mcreate\u001B[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001B[0m\n\u001B[1;32m    151\u001B[0m         )\n\u001B[1;32m    152\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 153\u001B[0;31m         response, _, api_key = requestor.request(\n\u001B[0m\u001B[1;32m    154\u001B[0m             \u001B[0;34m\"post\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m             \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/openai/lib/python3.9/site-packages/openai/api_requestor.py\u001B[0m in \u001B[0;36mrequest\u001B[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    224\u001B[0m             \u001B[0mrequest_timeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrequest_timeout\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    225\u001B[0m         )\n\u001B[0;32m--> 226\u001B[0;31m         \u001B[0mresp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgot_stream\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_interpret_response\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstream\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    227\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mresp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgot_stream\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapi_key\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/openai/lib/python3.9/site-packages/openai/api_requestor.py\u001B[0m in \u001B[0;36m_interpret_response\u001B[0;34m(self, result, stream)\u001B[0m\n\u001B[1;32m    617\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    618\u001B[0m             return (\n\u001B[0;32m--> 619\u001B[0;31m                 self._interpret_response_line(\n\u001B[0m\u001B[1;32m    620\u001B[0m                     \u001B[0mresult\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"utf-8\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    621\u001B[0m                     \u001B[0mresult\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatus_code\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/openai/lib/python3.9/site-packages/openai/api_requestor.py\u001B[0m in \u001B[0;36m_interpret_response_line\u001B[0;34m(self, rbody, rcode, rheaders, stream)\u001B[0m\n\u001B[1;32m    680\u001B[0m         \u001B[0mstream_error\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstream\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m\"error\"\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mresp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    681\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mstream_error\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;36m200\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0mrcode\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m300\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 682\u001B[0;31m             raise self.handle_error_response(\n\u001B[0m\u001B[1;32m    683\u001B[0m                 \u001B[0mrbody\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrcode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrheaders\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstream_error\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstream_error\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    684\u001B[0m             )\n",
      "\u001B[0;31mRateLimitError\u001B[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "fewshot_input = fewshot_data[0]\n",
    "fewshot_output = fewshot_data[1]\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "output_batches = 1\n",
    "\n",
    "df_output = pd.DataFrame()\n",
    "i = 0\n",
    "while output_batches > 0:\n",
    "    i += 1\n",
    "    data = {\"word\": [], \"label_GPT3\": [], \"label_ChatGPT_prompt\": [], \"label_ChatGPT_chat\": [], \"label_Ground_truth\": []}\n",
    "    input_text = \" \".join(df_train.prompt[i:i + 10])\n",
    "    prompt = f\"\"\"In following I want to find grammatical mistakes, where {{c}} means grammatically correct and {{i}} means grammatically incorrect.\n",
    "    If input be ***{{{fewshot_input}}}*** the output is ***{{{fewshot_output}}}***\n",
    "    If input be ***{{{input_text}}}*** the output is ***{{\"\"\"\n",
    "\n",
    "    data[\"word\"] = list(df[sentence_firsts[i*10]: sentence_firsts[i*10 + 10]].word)\n",
    "    data[\"label_Ground_truth\"] = list(df[sentence_firsts[i*10]: sentence_firsts[i*10 + 10]].label)\n",
    "\n",
    "    #Using GPT3\n",
    "    response_GPT3 = openai.Completion.create(\n",
    "      model=\"text-davinci-003\",\n",
    "      prompt=prompt,\n",
    "      temperature=0.5,\n",
    "      max_tokens=1000,\n",
    "      top_p=1.0,\n",
    "      frequency_penalty=0.0,\n",
    "      presence_penalty=0.0\n",
    "    )\n",
    "    output_GPT3 = response_GPT3.choices[0].text.split('}***')[0]\n",
    "    lines = output_GPT3.split(\"\\n\")  # split text into lines\n",
    "\n",
    "    # split each line into two columns and create a dictionary\n",
    "    for line in lines:\n",
    "        if line.strip():  # skip empty lines\n",
    "            columns = line.split(\"\\t\")\n",
    "            try:\n",
    "                data[\"label_GPT3\"].append(columns[1].strip())\n",
    "            except IndexError:\n",
    "                data[\"label_GPT3\"].append(\"\")\n",
    "    if len(data[\"word\"]) != len(data[\"label_GPT3\"]):\n",
    "        continue\n",
    "\n",
    "    #Using ChatGPT\n",
    "    response_ChatGPT_prompt = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    output_ChatGPT_prompt = response_ChatGPT_prompt.choices[0].message.content.split('}***')[0]\n",
    "\n",
    "    # split each line into two columns and create a dictionary\n",
    "    lines = output_ChatGPT_prompt.split(\"\\n\")  # split text into lines\n",
    "    for line in lines:\n",
    "        if line.strip():  # skip empty lines\n",
    "            columns = line.split(\"\\t\")\n",
    "            try:\n",
    "                data[\"label_ChatGPT_prompt\"].append(columns[1].strip())\n",
    "            except IndexError:\n",
    "                data[\"label_ChatGPT_prompt\"].append(\"\")\n",
    "    if len(data[\"word\"]) != len(data[\"label_ChatGPT_prompt\"]):\n",
    "        continue\n",
    "\n",
    "    response_ChatGPT_chat = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"In following I want to find grammatical mistakes in sentences. {{c}} means grammatically correct and {{i}} means grammatically incorrect. If input be ***{{{fewshot_input}}}*** the output is ***{{{fewshot_output}}}***\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"What is the sentences to label the grammar mistakes?\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Label grammatical mistakes of ***{{{fewshot_input}}}***\"},\n",
    "            {\"role\": \"assistant\", \"content\": fewshot_output},\n",
    "            {\"role\": \"user\", \"content\": f\"Label grammatical mistakes of ***{{{input_text}}}***\"}\n",
    "        ]\n",
    "    )\n",
    "    output_ChatGPT_chat = response_ChatGPT_chat.choices[0].message.content.split('}***')[0]\n",
    "    lines = output_ChatGPT_chat.split(\"\\n\")  # split text into lines\n",
    "\n",
    "    # split each line into two columns and create a dictionary\n",
    "    for line in lines:\n",
    "        if line.strip():  # skip empty lines\n",
    "            columns = line.split(\"\\t\")\n",
    "            try:\n",
    "                data[\"label_ChatGPT_chat\"].append(columns[1].strip())\n",
    "            except IndexError:\n",
    "                data[\"label_ChatGPT_chat\"].append(\"\")\n",
    "    if len(data[\"word\"]) != len(data[\"label_ChatGPT_chat\"]):\n",
    "        continue\n",
    "\n",
    "    # convert dictionary to DataFrame\n",
    "    df_dictionary = pd.DataFrame(data)\n",
    "    df_output = pd.concat([df_output, df_dictionary], ignore_index=True)\n",
    "    output_batches -= 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "      word label_GPT3 label_ChatGPT_prompt label_ChatGPT_chat  \\\n0       IT          c                    c                  c   \n1     SAID          c                    c                  c   \n2        :          c                    c                  c   \n3        '          c                    c                  c   \n4    DANNY          c                    c                  c   \n..     ...        ...                  ...                ...   \n146   HAVE          i                    i                  i   \n147     MY          c                    c                  c   \n148  MONEY          c                    c                  c   \n149   BACK          c                    c                  c   \n150      .          c                    c                  c   \n\n    label_Ground_truth  \n0                    c  \n1                    c  \n2                    c  \n3                    c  \n4                    c  \n..                 ...  \n146                  c  \n147                  c  \n148                  c  \n149                  c  \n150                  c  \n\n[151 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>label_GPT3</th>\n      <th>label_ChatGPT_prompt</th>\n      <th>label_ChatGPT_chat</th>\n      <th>label_Ground_truth</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>IT</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SAID</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>:</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>'</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DANNY</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>HAVE</td>\n      <td>i</td>\n      <td>i</td>\n      <td>i</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>MY</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>MONEY</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>BACK</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>.</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n      <td>c</td>\n    </tr>\n  </tbody>\n</table>\n<p>151 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output.to_csv('output_dev.csv')\n",
    "df_output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of GPT3\n",
      "Accuracy: 0.8807947019867549\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F0.5: 0.0\n",
      "******\n",
      "Evaluation of ChatGPT by prompt\n",
      "Accuracy: 0.9072847682119205\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F0.5: 0.0\n",
      "******\n",
      "Evaluation of ChatGPT by chat\n",
      "Accuracy: 0.9072847682119205\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F0.5: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, fbeta_score\n",
    "df_output = df_output.replace({'c':0, 'i':1})\n",
    "\n",
    "# true labels\n",
    "y_true = list(df_output.label_Ground_truth)\n",
    "\n",
    "# Evaluate GPT3\n",
    "y_pred = list(df_output.label_GPT3)\n",
    "print(\"Evaluation of GPT3\")\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred)}\")\n",
    "print(f\"F0.5: {fbeta_score(y_true, y_pred, beta=0.5)}\")\n",
    "print(\"******\")\n",
    "\n",
    "\n",
    "y_pred = list(df_output.label_ChatGPT_prompt)\n",
    "print(\"Evaluation of ChatGPT by prompt\")\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred)}\")\n",
    "print(f\"F0.5: {fbeta_score(y_true, y_pred, beta=0.5)}\")\n",
    "print(\"******\")\n",
    "\n",
    "\n",
    "y_pred = list(df_output.label_ChatGPT_chat)\n",
    "print(\"Evaluation of ChatGPT by chat\")\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred)}\")\n",
    "print(f\"F0.5: {fbeta_score(y_true, y_pred,beta=0.5)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "clf = pickle.load(open('classifier.sav', 'rb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '{i}'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/lv/4wjmh6d51zv3p9ttk4670pq80000gn/T/ipykernel_21389/4098925706.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf_output\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'label_GPT3'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'label_ChatGPT_prompt'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'label_ChatGPT_chat'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Evaluation of SVM\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Accuracy: {accuracy_score(y_true, y_pred)}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Precision: {precision_score(y_true, y_pred)}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Recall: {recall_score(y_true, y_pred)}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/openai/lib/python3.9/site-packages/sklearn/naive_bayes.py\u001B[0m in \u001B[0;36mpredict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m     80\u001B[0m         \"\"\"\n\u001B[1;32m     81\u001B[0m         \u001B[0mcheck_is_fitted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 82\u001B[0;31m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_X\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     83\u001B[0m         \u001B[0mjll\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_joint_log_likelihood\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     84\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclasses_\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjll\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/openai/lib/python3.9/site-packages/sklearn/naive_bayes.py\u001B[0m in \u001B[0;36m_check_X\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m   1145\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_check_X\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1146\u001B[0m         \u001B[0;34m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1147\u001B[0;31m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_X\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1148\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbinarize\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1149\u001B[0m             \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbinarize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthreshold\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbinarize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/openai/lib/python3.9/site-packages/sklearn/naive_bayes.py\u001B[0m in \u001B[0;36m_check_X\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    517\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_check_X\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    518\u001B[0m         \u001B[0;34m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 519\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"csr\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    520\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    521\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_check_X_y\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/openai/lib/python3.9/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    564\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Validation should be done on X, y or both.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    565\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mno_val_y\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 566\u001B[0;31m             \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    567\u001B[0m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    568\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mno_val_y\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/openai/lib/python3.9/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[1;32m    744\u001B[0m                     \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcasting\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"unsafe\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    745\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 746\u001B[0;31m                     \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    747\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mComplexWarning\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    748\u001B[0m                 raise ValueError(\n",
      "\u001B[0;32m~/opt/anaconda3/envs/openai/lib/python3.9/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m__array__\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m   2062\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2063\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__array__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnpt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDTypeLike\u001B[0m \u001B[0;34m|\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2064\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2065\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2066\u001B[0m     def __array_wrap__(\n",
      "\u001B[0;31mValueError\u001B[0m: could not convert string to float: '{i}'"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(df_output[['label_GPT3', 'label_ChatGPT_prompt', 'label_ChatGPT_chat']])\n",
    "print(\"Evaluation of Naive Bayes\")\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred)}\")\n",
    "print(f\"F0.5: {fbeta_score(y_true, y_pred, beta=0.5)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
